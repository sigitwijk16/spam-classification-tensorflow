{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"signature_name\": \"serving_default\", \"instances\": [\"Cq8DCqwDCgR0ZXh0EqMDCqADCp0DRGVhciBWYWx1ZWQgQ3VzdG9tZXIsIENvbmdyYXR1bGF0aW9ucyEgWW91J3ZlIGJlZW4gc2VsZWN0ZWQgZm9yIGFuIGV4Y2x1c2l2ZSBvcHBvcnR1bml0eSB0byByZWNlaXZlIGEgc3BlY2lhbCBnaWZ0LCBhYnNvbHV0ZWx5IEZSRUUhIEJ1dCBodXJyeSwgdGhpcyBvZmZlciBpcyBvbmx5IGF2YWlsYWJsZSBmb3IgYSBsaW1pdGVkIHRpbWUhIENsYWltIHlvdXIgZnJlZSBnaWZ0IG5vdyBieSBjbGlja2luZyB0aGUgbGluayBiZWxvdyBhbmQgZW50ZXJpbmcgeW91ciBkZXRhaWxzLCBDbGFpbSBZb3VyIEZyZWUgR2lmdCBOb3cuIERvbid0IG1pc3Mgb3V0IG9uIHRoaXMgYW1hemluZyBvcHBvcnR1bml0eSB0byBnZXQgc29tZXRoaW5nIGZvciBub3RoaW5nISBBY3QgZmFzdCBiZWZvcmUgaXRzIHRvbyBsYXRlISBXYXJtIFJlZ2FyZHM=\"]}\n",
      "Error: {\n",
      "    \"error\": \"Could not parse example input, value: 'Cq8DCqwDCgR0ZXh0EqMDCqADCp0DRGVhciBWYWx1ZWQgQ3VzdG9tZXIsIENvbmdyYXR1bGF0aW9ucyEgWW91J3ZlIGJlZW4gc2VsZWN0ZWQgZm9yIGFuIGV4Y2x1c2l2ZSBvcHBvcnR1bml0eSB0byByZWNlaXZlIGEgc3BlY2lhbCBnaWZ0LCBhYnNvbHV0ZWx5IEZSRUUhIEJ1dCBodXJyeSwgdGhpcyBvZmZlciBpcyBvbmx5IGF2YWlsYWJsZSBmb3IgYSBsaW1pdGVkIHRpbWUhIENsYWltIHlvdXIgZnJlZSBnaWZ0IG5vdyBieSBjbGlja2luZyB0aGUgbGluayBiZWxvdyBhbmQgZW50ZXJpbmcgeW91ciBkZXRhaWxzLCBDbGFpbSBZb3VyIEZyZWUgR2lmdCBOb3cuIERvbid0IG1pc3Mgb3V0IG9uIHRoaXMgYW1hemluZyBvcHBvcnR1bml0eSB0byBnZXQgc29tZXRoaW5nIGZvciBub3RoaW5nISBBY3QgZmFzdCBiZWZvcmUgaXRzIHRvbyBsYXRlISBXYXJtIFJlZ2FyZHM='\\n\\t [[{{function_node __inference_serve_tf_examples_fn_271272}}{{node ParseExample/ParseExampleV2}}]]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import tensorflow as tf\n",
    "\n",
    "def prepare_example(message):\n",
    "  feature = {\n",
    "      \"text\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[message.encode()])),\n",
    "  }\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "  example_str = example.SerializeToString()\n",
    "\n",
    "  encoded_example = base64.b64encode(example_str).decode('utf-8')\n",
    "\n",
    "  # Create the JSON data with the encoded example\n",
    "  json_data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": [encoded_example]})\n",
    "\n",
    "  return json_data\n",
    "\n",
    "\n",
    "def predict_with_model_server(message):\n",
    "  json_data = prepare_example(message)\n",
    "  print(json_data)\n",
    "\n",
    "  endpoint = 'http://localhost:8080/v1/models/spam-classification-model:predict'\n",
    "\n",
    "  response = requests.post(endpoint, data=json_data)\n",
    "\n",
    "  prediction = response.json().get(\"predictions\")\n",
    "\n",
    "  if prediction:\n",
    "    prediction_value = prediction[0][0]\n",
    "    return f\"Prediction: {prediction_value}\"\n",
    "  else:\n",
    "    return f\"Error: {response.text}\"\n",
    "\n",
    "message = \"Dear Valued Customer, Congratulations! You've been selected for an exclusive opportunity to receive a special gift, absolutely FREE! But hurry, this offer is only available for a limited time! Claim your free gift now by clicking the link below and entering your details, Claim Your Free Gift Now. Don't miss out on this amazing opportunity to get something for nothing! Act fast before its too late! Warm Regards\"\n",
    "\n",
    "prediction = predict_with_model_server(message)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'examples:0' shape=(None,) dtype=string>, <tf.Tensor 'unknown:0' shape=() dtype=resource>, <tf.Tensor 'unknown_0:0' shape=() dtype=int64>, <tf.Tensor 'unknown_1:0' shape=() dtype=string>, <tf.Tensor 'unknown_2:0' shape=() dtype=int64>, <tf.Tensor 'unknown_3:0' shape=() dtype=resource>, <tf.Tensor 'unknown_4:0' shape=() dtype=resource>, <tf.Tensor 'unknown_5:0' shape=() dtype=resource>, <tf.Tensor 'unknown_6:0' shape=() dtype=resource>, <tf.Tensor 'unknown_7:0' shape=() dtype=resource>, <tf.Tensor 'unknown_8:0' shape=() dtype=resource>, <tf.Tensor 'unknown_9:0' shape=() dtype=resource>, <tf.Tensor 'unknown_10:0' shape=() dtype=resource>, <tf.Tensor 'unknown_11:0' shape=() dtype=resource>, <tf.Tensor 'unknown_12:0' shape=() dtype=resource>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.saved_model.load(\"C:/Users/kicot/Tugas/colab/c-spam-pipeline/serving_model_dir/spam-classification-model/1715276941\")\n",
    "\n",
    "print(model.signatures[\"serving_default\"].inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Windows Powershell Script \n",
    "\n",
    "docker run -t --rm -d -p 8501:8501 -v \"C:/Users/kicot/Tugas/colab/c-spam-pipeline/serving_model_dir/spam-classification-model/1715276941:/models/spam-classification-model/1\" -e MODEL_NAME=spam-classification-model tensorflow/serving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
